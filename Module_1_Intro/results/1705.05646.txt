1705.05646v1 [cs.DC] 16 May 2017

arXiv

Quadratic and Near-Quadratic Lower Bounds

for the CONGEST Model*

Keren Censor-Hillel Seri Khoury Ami Paz
May 17, 2017

Abstract

We present the first super-linear lower bounds for natural graph problems in the CON-
GEST model, answering a long-standing open question.

Specifically, we show that any exact computation of a minimum vertex cover or a max-
imum independent set requires Q(n?/ log? n) rounds in the worst case in the CONGEST
model, as well as any algorithm for y-coloring a graph, where y is the chromatic number
of the graph. We further show that such strong lower bounds are not limited to NP-hard
problems, by showing two simple graph problems in P which require a quadratic and near-
quadratic number of rounds.

Finally, we address the problem of computing an exact solution to weighted all-pairs-
shortest-paths (APSP), which arguably may be considered as a candidate for having a
super-linear lower bound. We show a simple Q(n) lower bound for this problem, which
implies a separation between the weighted and unweighted cases, since the latter is known
to have a complexity of O(n/logn). We also formally prove that the standard Alice-Bob
framework is incapable of providing a super-linear lower bound for exact weighted APSP,
whose complexity remains an intriguing open question.

“Department of Computer Science, Technion, {ckeren,serikhoury,amipaz}@cs.technion.ac.il.
part by ISF grant 1696/14.

Supported in
/n/n1 Introduction

It is well-known and easily proven that many graph problems are global for distributed comput-
ing, in the sense that solving them necessitates communication throughout the network. This
implies tight O(D) complexities, where D is the diameter of the network, for global problems in
the LOCAL model. In this model, a message of unbounded size can be sent over each edge in
each round, which allows to learn the entire topology in D rounds. Global problems are widely
studied in the CONGEST model, in which the size of each message is restricted to O(log n)
bits, where n is the size of the network. The trivial complexity of learning the entire topology
in the CONGEST model is O(m), where m is the number of edges of the communication graph,
and since m can be as large as O(n”), one of the most basic questions for a global problem is
how fast in terms of n it can be solved in the CONGEST model.

Some global problems admit fast O(D)-round solutions in the CONGEST model, such as
constructing a breadth-first search tree 59). Some others have complexities of 0(D + Vn),
such as constructing a minimum spanning tree, and various approximation and verification
problems (60) . Some problems are yet harder, with complexities that are near-
inear in n {1))32)|41}|51\|60|. For some problems, no O(n) solutions are known and they are
candidates to being even harder that the ones with linear-in-n complexities.

A major open question about global graph problems in the CONGEST model is whether
natural graph problems for which a super-linear number of rounds is required indeed exist. In
his paper, we answer this question in the affirmative. That is, our conceptual contribution is
hat there exist super-linearly hard problems in the CONGEST model. In fact, the
ower bounds that we prove in this paper are as high as quadratic in n, or quadratic up to
ogarithmic factors, and hold even for networks of a constant diameter. Our lower bounds also
imply linear and near-linear lower bounds for the CLIQUE-BROADCAST model.
We note that high lower bounds for the CONGEST model may be obtained rather artificially,
vy forcing large inputs and outputs that must be exchanged. However, we emphasize that all
he problems for which we show our lower bounds can be reduced to simple decision problems,
where each node needs to output a single bit. All inputs to the nodes, if any, consist of edge
weights that can be represented by polylogn bits.
Technically, we prove a lower bound of Q(n?/ log? n) on the number of rounds required for
computing an exact minimum vertex cover, which also extends to computing an exact maximum
independent set (Section 3.1). This is in stark contrast to the recent O(log A/ log log A)-round
algorithm of [8] for obtaining a (2 + €)-approximation to the minimum vertex cover. Similarly,
we give an Q(n?/ log? n) lower bound for 3-coloring a 3-colorable graph, which extends also for
deciding whether a graph is 3-colorable, and also implies the same hardness for computing the
chromatic number y or computing a x-coloring (Section [B.2). These lower bounds hold even for
randomized algorithms which succeed with high probability.

An immediate question that arises is whether only NP-hard problems are super-linearly
hard in the CONGEST model. In Section [4] we provide a negative answer to such a postulate,
by showing two simple problems that admit polynomial-time sequential algorithms, but in the
CONGEST model require Q(n?) rounds (identical subgraph detection) or Q(n?/logn) rounds
(weighted cycle detection). The latter also holds for randomized algorithms, while for the
former we show a randomized algorithm that completes in O(D) rounds, providing the strongest
possible separation between deterministic and randomized complexities for global problems in
the CONGEST model.

Finally, we address the intriguing open question of the complexity of computing exact
weighted all-pairs-shortest-paths (APSP) in the CONGEST model. While the complexity of the
unweighted version of APSP is O(n/logn), as follows from (32)[42),

the complexity of weighted

‘We say that an event occurs with high probability (w-h.p) if it occurs with probability * for some constant
e>0.
/n/nAPSP remains largely open, and only recently the first sub-quadratic algorithm was given in (28).
With the current state-of-the-art, this problem could be considered as a suspect for having a
super-linear complexity in the CONGEST model. While we do not pin-down the complexity of
weighted APSP in the CONGEST model, we provide a truly linear lower bound of Q(n) rounds
for it, which separates its complexity from that of the unweighted case. Moreover, we argue
that it is not a coincidence that we are currently unable to show super-linear lower bound for
weighted APSP, by formally proving that the commonly used framework of reducing a 2-party
communication problem to a problem in the CONGEST model cannot provide a super-linear
lower bound for weighted APSP, regardless of the function and the graph construction used
(Section 5). This implies that obtaining any super-linear lower bound for weighted
APSP provably requires a new technique.

1.1 The Challenge

Many lower bounds for the CONGEST model rely on reductions from 2-party communication
problems (see, e.g., 725 6 [57|(61)]64)). In this setting, two players, Alice and Bob,
are given inputs of K bits and need to a single output a bit according to some given function
of their inputs. One of the most common problem for reduction is Set Disjointness, in which
the players need to decide whether there is an index for which both inputs are 1. That is, if
the inputs represent subsets of {0,..., A — 1}, the output bit of the players needs to indicate
whether their input sets are disjoint. The communication complexity of 2-party Set Disjointness
is known to be O(K) (49).

In a nutshell, there are roughly two standard frameworks for reducing the 2-party commu-
nication problem of computing a function f to a problem P in the CONGEST model. One
of these frameworks works as follows. A graph construction is given, which consists of some
fixed edges and some edges whose existence depends on the inputs of Alice and Bob. This
graph should have the property that a solution to P over it determines the solution to f. Then,
given an algorithm ALG for solving P in the CONGEST model, the vertices of the graph are
split into two disjoint sets, V4 and Vg, and Alice simulates ALG over V4 while Bob simulates
ALG over Vg. The only communication required between Alice and Bob in order to carry
out this simulation is the content of messages sent in each direction over the edges of the cut
C = E(V4,Vz). Therefore, given a graph construction with a cut of size |C| and inputs of size
& for a function f whose communication complexity on K bits is at least CC(f), the round
complexity of ALG is at least Q(CC(f)/|C| log n).

The challenge in obtaining super-linear lower bounds was previously that the cuts in the
graph constructions were large compared with the input size kK. For example, the graph con-
struction for the lower bound for computing the diameter in has K = @(n?) and |C| = @(n),
which gives an almost linear lower bound. The graph construction in for the lower bound
for computing a (3/2 —)-approximation to the diameter has a smaller cut of |C| = O(./n), but
this comes at the price of supporting a smaller input size K = O(n), which gives a lower bound
that is roughly a square-root of n.

To overcome this difficulty, we leverage the recent framework of (2), which provides a bit-
gadget whose power is in allowing a logarithmic-size cut. We manage to provide a graph
construction that supports inputs of size K = @(n?) in order to obtain our lower bounds for
minimum vertex cover, maximum independent set and 3-coloring?| The latter is also inspired by,
and is a simplification of, a lower bound construction for the size of proof labelling schemes {33}.

Further, for the problems in P that we address, the cut is as small as |C| = O(1). For one of
the problems, the size of the input is such that it allows us to obtain the highest possible lower
bound of Q(n?) rounds.

?Tt can also be shown, by simple modifications to our constructions, that these problems require Q(m) rounds,
for graphs with m edges.
/n/nWith respect to the complexity of the weighted APSP problem, we show an embarrassingly
simple graph construction that extends a construction of (56), which leads to an Q(n) lower
bound. However, we argue that a new technique must be developed in order to obtain any super-
linear lower bound for weighted APSP. Roughly speaking, this is because given a construction
with a set S of nodes that touch the cut, Alice and Bob can exchange O(|S|n log n) bits which
encode the weights of all lightest paths from any node in their set to a node in S. Since
the cut has ((|S|) edges, and the bandwidth is O(log), this cannot give a lower bound of
more than Q(n) rounds. With some additional work, our proof can be carried over to a larger
number of players at the price of a small logarithmic factor, as well as to the second Alice-Bob
framework used in previous work (e.g. (64)), in which Alice and Bob do not simulate nodes in
a fixed partition, but rather in decreasing sets that partially overlap. Thus, determining the
complexity of weighted APSP requires new tools, which we leave as a major open problem.

1.2 Additional Related Work

Vertex Coloring, Minimum Vertex Cover, and Maximum Independent Set: One of
the most central problems in graph theory is vertex coloring, which has been extensively studied
in the context of distributed computing (see, e.g., [55] 62)(65) and
references therein). The special case of finding a (A + 1)-coloring, where A is the maximum
degree of a node in the network, has been the focus of many of these studies, but is a local
problem, which can be solved in much less than a sublinear number of rounds.

Another classical problem in graph theory is finding a minimum vertex cover (MVC). In dis-
tributed computing, the time complexity of approximating MVC has been addressed in several
cornerstone studies (5}{6)[8}[14}/34} |63}.

Observe that finding a minimum size vertex cover is equivalent to finding a maximum size
independent set. However, these problems are not equivalent in an approximation-preserving
way. Distributed approximations for maximum independent set has been studied in (7[15]22]53).

Distance Computations: Distance computation problems have been widely studied in the
CONGEST model for both weighted and unweighted networks {1/32/38} [42}|50)(51}(56}(60). One
of the most fundamental problems of distance computations is computing all pairs shortest
paths. For unweighted networks, an upper bound of O(n/logn) was recently shown by [42],
matching the lower bound of (32). Moreover, the possibility of bypassing this near-linear barrier
for any constant approximation factor was ruled out by (56). For the weighted case, however,
we are still very far from understanding the complexity of APSP, as there is still a huge gap

between the upper and lower bounds. Recently, Elkin showed an O(n3 . log? (n) upper
bound for weighted APSP, while the previously highest lower bound was the near-linear lower
bound of (which holds also for any (poly n)-approximation factor in the weighted case).
Distance computation problems have also been considered in the CONGESTED-CLIQUE
model [38}(40), in which the underlying communication network forms a clique. In this
model showed that unweighted APSP, and a (1+ 0(1))-approximation for weighted APSP,
can be computed in O(n°-18)

rounds.

Subgraph Detection: The problem of finding subgraphs of a certain topology has received a
lot of attention in both the sequential and the distributed settings (see, e.g.,
and references therein). The problems of finding paths of length 4 or 5 with zero weight
are also related to other fundamental problems, notable in our context is APSP [2].

/n/n2 Preliminaries

2.1 Communication Complexity

In a two-party communication complexity problem (49), there is a function f : {0, 1y* x
{0, 1 — {TRUE, FALSE}, and two players, Alice and Bob, who are given two input strings,
x,y € {0, 1%, respectively, that need to compute f(x,y). The communication complexity of
a protocol 7 for computing f, denoted CC(z), is the maximal number of bits Alice and Bob
exchange in 7, taken over all values of the pair (x,y). The deterministic communication com-
plexity of f, denoted CC(f), is the minimum over C'C(z), taken over all deterministic protocols
nm that compute f.

In a randomized protocol 7, Alice and Bob may each use a random bit string. A randomized
protocol 7 computes f if the probability, over all possible bit strings, that 7 outputs f(2,y) is
at least 2/3. The randomized communication complexity of f, CC®(f), is the minimum over
CC(r), taken over all randomized protocols 7 that compute f.

In the Set Disjointness problem (DISJx), the function f is DISJx (x,y), whose output is
FALSE if there is an index i € {0,...,& —1} such that x; = y; = 1, and TRUE otherwise. In
the Equality problem (EQ;,), the function f is EQx (x,y), whose output is TRUE if x = y, and
FALSE otherwise.

Both the deterministic and randomized communication complexities of the DISJx problem
are known to be Q(K) Example 3.22]. The deterministic communication complexity of

EQx is in Q(K) Example 1.21], while its randomized communication complexity is in
O(log K) Example 3.9].

2.2 Lower Bound Graphs

To prove lower bounds on the number of rounds necessary in order to solve a distributed
problem in the CONGEST model, we use reductions from two-party communication complexity
problems. To formalize them we use the following definition.

Definition 1. (Family of Lower Bound Graphs)

Fix an integer K, a function f : {0, 1y* x {0, 1y* — {TRUE, FALSE} and a predicate P for
graphs. The family of graphs {Gry = (V, Exy) | x,y € {0, 1%}, is said to be a family of lower
bound graphs w.r.t. f and P if the following properties hold:

(1) The set of nodes V is the same for all graphs, and we denote by V = V4UVp a fired
partition of it;

(2) Only the existence or the weight of edges in V4 x V4 may depend on x;
(3) Only the existence or the weight of edges in Vg x Vg may depend on y;
G,, satisfies the predicate P 4 x,y) = TRUE.
y P oY

We use the following theorem, which is standard in the context of communication complexity-
based lower bounds for the CONGEST model (see, e.g. |40}) Its proof is by a standard

simulation argument.

Theorem 1. Fiz a function f : {0, 1y* x {0, 1y* — {TRUE, FALSE} and a predicate P. If there is
a family {Gz} of lower bound graphs with C = E(Va, Vg) then any deterministic algorithm for
deciding P in the CONGEST model requires Q(CC(f)/|C|logn) rounds, and any randomized
algorithm for deciding P in the CONGEST model requires Q(CC®(f)/|C|logn) rounds.

Proof. Let ALG be a distributed algorithm in the CONGEST model that decides P in T' rounds.
Given inputs z,y € {0, 1y* to Alice and Bob, respectively, Alice constructs the part of Gz
/n/nfor the nodes in V4 and Bob does so for the nodes in Vg. This can be done by items (1),(2)
and (3) in Definition []] and since {Gz,y} satisfies this definition. Alice and Bob simulate ALG
by exchanging the messages that are sent during the algorithm between nodes of V4 and nodes
of Vg in either direction. (The messages within each set of nodes are simulated locally by the
corresponding player without any communication). Since item (4) in Definition [1] also holds,
we have that Alice and Bob correctly output f(z,y) based on the output of ALG. For each
edge in the cut, Alice and Bob exchange O(logn) bits per round. Since there are T rounds
and |C| edges in the cut, the number of bits exchanged in this protocol for computing f is
O(T |C|logn). The lower bounds for T now follows directly from the lower bounds for CC(f)
and CCR (f).

In what follows, for each decision problem addressed, we describe a fixed graph construction
G = (V,E), which we then generalize to a family of graphs {Gry = (V, Ex,y) | «,y € {0, 1%},
which we show to be a family lower bound graphs w.r.t. to some function f and the requirec
predicate P. By Theorem and the known lower bounds for the 2-party communication
problem, we deduce a lower bound for any algorithm for deciding P in the CONGEST model.

Remark: For our constructions which use the Set Disjointness function as f, we need to exclude
he possibilities of all-1 input vectors. This is for the sake of guaranteeing that the graphs are
connected, in order to avoid trivial impossibilities. However, this restriction does not change
he asymptotic bounds for Set Disjointness, since computing this function while excluding all-1
input vectors can be reduced to computing this function for inputs that are shorter by one bit
by having the last bit be fixed to 0).

3  Near-Quadratic Lower Bounds for NP-Hard Problems

3.1 Minimum Vertex Cover

The first near-quadratic lower bound we present is for computing a minimum vertex cover, as
stated in the following theorem.

Theorem 2. Any distributed algorithm in the CONGEST model for computing a minimum ver-
tex cover or for deciding whether there is a vertex cover of a given size M requires Q(n?/ log? n)
rounds.

Finding the minimum size of a vertex cover is equivalent to finding the maximum size of a
maximum independent set, because a set of nodes is a vertex cover if and only if its complement
is an independent set. Thus, Theorem [3] is a direct corollary of Theorem [2}

Theorem 3. Any distributed algorithm in the CONGEST model for computing a maximum
independent set or for deciding whether there is an independent set of a given size requires
Q(n2/ log? n) rounds.

Observe that a lower bound for deciding whether there is a vertex cover of some given
size M or not implies a lower bound for computing a minimum vertex cover. This is because
computing the size of a given subset of nodes can be easily done in O(D) rounds using standard
tools. Therefore, to prove Theorem |2] it is sufficient to prove its second part. We do so by
describing a family of lower bound graphs with respect to the Set Disjointness function and the
predicate P that says that the graph has a vertex cover of size M. We begin with describing
the fixed graph construction G = (V, £) and then define the family of lower bound graphs and
analyze its relevant properties.

The fixed graph construction: Let k be a power of 2. The fixed graph (Figure [I) consists
/n/nFigure 1: The family of lower bound graphs for deciding the size of a vertex cover, with many edges
omitted for clarity. The node a¥~! is connected to all the nodes in T4,, and a} is connected to to, and
to all the nodes in F4, \ {f9,}- Examples of edges from 6? and b§ to the bit-gadgets are also given. An
additional edge, which is among the edges corresponding to the strings x and y, is {b9,b4}, while the
edge {a}, a9} does not exist. Here, xo,9 = 1 and yo1 = 0.

of four cliques of size k: Ay, = {a) |O<i<k-1I}, Ay = {a |0<i<k- }, Bi = {bi 0<
i<k—1} and Bo = {b, |0<i<k—1}. In addition, for each set S € {A1, Ao, Bi, Bo}, there
are two corresponding sets of nodes of size logk, denoted Fs = {f% | 0 < h < logk— 1} and
Ts = {th <logk — 1}. The latter are called bit-gadgets and their nodes are bit-nodes.
The bit-nodes are partitioned me 2logk 4-cycles: for each h € {0,...,logk — 1} and €€
{1,2}, we connect the 4-cycle (f" hyo tlh of Bp th,)- Note that there are no edges between pairs of

nodes denoted fh, or between pairs of nodes denoted th.

The nodes of each set S € {A;, Az, Bi, By} are connected to nodes in the corresponding
set of bit-nodes, according to their binary representation, as folios. Let sh be a node in a set
S € {A1, Ao, Bi, Bo}, ie. s € {a,b}, 2 {1,2} andi {0,...,4—1}, and let ¢), denote the bit
number h in the binary representation of ¢. For such a node ; , "lefims bin( (sh) ={ fi |i, = 0} U
{th in = 1}, and connect si by an edge to each of the nodes in bin(s}). The next two claims
address the basic properties of vertex covers of G.

Claim 1. Any vertex cover of G must contain at least k — 1 nodes from each of the clique
Ai, Ao, Bi and Bo, and at least 4log k bit-nodes.

Proof. In order to cover all the edges of each if the cliques on A;, Ag, By; and Bo, any vertex

cover must contain at least k — 1 nodes of the clique. For each h € {0,...,logk — 1} anc
£ € {1,2}, in order to cover the edges of the 4-cycle ( fh th, fe Bet Bs any vertex cover must
contain at least two of the cycle nodes.

Claim 2. IPU i CV is a vertex cover of G of size 4(k — 1) + 4logk, then there are two indices
i,j € {0,...,k —1} such that a‘,a}, bib) are not in U.

Proof. By Claim [I] [1] U must contain k — 1 nodes from each clique A1, Ao, a and By, and 4 log k
bit-nodes, so it must not contain one node from each clique. Let a‘, a3, b oh, be the nodes in
Aj, Ag, Bi, Bz which are not in U, respectively. To cover the edges connecting a‘, to bin(a\), U
must contain all the nodes of bin(ai), and similarly, U must contain all the nodes of bin(bi).
If i A 7’ then there is an index h € {0,...,logk—1} such that i, 4 i,, so one of the edges
/n/n(fi A th ,) or (th, th.) is not covered by U. Thus, it must hold that i = i’. A similar argument
shows j = j’.

Adding edges corresponding to the strings « and y: Given two binary strings x,y €
{0, yy, we augment the graph G defined above with additional “ees. which defines Gy.
Assume that x and y are indexed by pairs of the form (i,j) € {0,.. - 1}. For each such
pair (i, j) we add to Gry the following edges. If x;,; = 0, then we ca an edge between the
nodes a‘ and a3, and if yi,; = 0 then we add an edge between the nodes bi, and b. To prove
that {G,,} is a family of lower bound graphs, it remains to prove the next lemma.

Lemma 1. The graph Gzy has a vertex cover of cardinality M = 4(k — 1) + 4logk iff
DISJ(x, y) = FALSE.

Proof. For the first implication, assume that DISJ(x,y) = FALSE and let i,j € {0,...,k—1}
be such that 2; = yij = 1. Note that in this case a‘, is not connected to a4, and bi, is not
connected to b}. We define a set U C V as the union of the two sets of nodes (Aj \ {a S})U (Ae \
{a}}) U (By \ {bh }) U (Bo \ {0} )¥) and bin(a4,) U bin(a3) U bin(b4) U bin(b3), and show that U is a
vertex cover of Gy.

First, U covers all the edges inside the cliques Ai, A2, Bi and Bg, as it contains k — 1 nodes
from each clique. These nodes also cover all the edges connecting nodes in A, to nodes in
Ay and all the edges connecting nodes in B, to nodes in By. Furthermore, U covers any edge
connecting some node u € (A1\ {ai })U(A2 \ {a3 })U (Bi \ {bi }) U (Bo \ {05}) with the bit-gadgets.
For each node s € ai, a, bi, bh, the nodes bin(s) are in U, so U also cover the edges connecting
s to ue bit gadget. Finally, U covers all the edges inside the bit gadgets, as from each 4-cycle
(fi Apt qo fh, th ) it contains two non-adjacent nodes: if i, = 0 then fh 3h € U and otherwise
th ‘Ay? th € U, and if jn = 0 then Shy tbo € U and otherwise tht €U. We thus have that U
is a vertex cover of size 4(k — 1) + 4logk, as needed.

For the other implication, let U C V be a vertex cover of Gz, of size 4(k — 1) + 4logk.
As the set of edges of G is contained in ‘ne set of edges of Gay, Ui is also a cover of G, anc
by Claim [2] there are indices i,j € {0,.. — 1} such that a‘, a3, bib are not in U. Since
U is a cover, the graph does not contain. the edges (ai, a3) and (bi,b3), so we conclude tha
£7 = Yj = 1, which implies that DISJ(x, y) = FALSE.

Having constructed the family of lower bound graphs, we are now ready to prove Theorem]

Proof of Theorem To complete the proof of Theorem |[2| we divide the nodes of G (which
are also the nodes of Gz,y) into two sets. Let V4 = A; U Ag U Fa, U Ta, U Fay UT, anc
Vp = V\V4. Note that n € O(k), and thus K = |a| = |y| = O(n). Furthermore, note that the
only edges in the cut E(V4, Vg) are the edges between nodes in {F'4, UT4, U F4, UT4,} anc
nodes in {f'g, UTp, UF'B, UTp, }, which are in total O(log n) edges. Since Lemma|l] shows tha
{Gz} is a family of lower bound graphs, we can apply Theorem [I] on the above partition to
deduce that because of the lower bound for Set Disjointness, any algorithm in the CONGEST
model for deciding whether a given graph has a cover of cardinality M = 4(k — 1) + 4logk
requires at least Q(K/log?(n)) = 2(n?/log?(n)) rounds.

3.2. Graph Coloring

Given a graph G, we denote by y(G) the minimal number of colors in a proper vertex-coloring
of G. In this section we consider the problems of coloring a graph in x colors, computing x and
approximating it. We prove the next theorem.

Theorem 4. Any distributed algorithm in the CONGEST model that colors a x-colorable graph
G in x colors or compute x(G) requires Q(n?/ log? n) rounds.
/n/nThese are copies of the
— i

above triangles

Figure 2: The family of lower bound graphs for coloring, with many edges omitted for clarity. The node
C} is connected to all the nodes in F4, UT'4, and C} is connected to all the nodes in Fg, UTp,. The
node C? is connected to all the nodes in F4, UT'4, and C? is connected to all the nodes in Fg, UTp,.

Any distributed algorithm in the CONGEST model that decides if x(G) < ¢ for a given
integer c, requires O((n — c)?/(clogn + log? n)) rounds.

We give a detailed lower bound construction for the first part of the theorem, by showing
that distinguishing y < 3 from x > 4 is hard. Then, we extend our construction to deal with
deciding whether y < c.

The fixed graph construction: We describe a family of lower bound graphs, which builds
upon the family of graphs defined in Section 3-1] We define G = (V, E) as follows (see Figure|2).

There are four sets of size k: Ay = fa‘, |O<i<k-1}, A= fai, |O<i<k-1},
Bl= {bi |O0<i<k-1} and BB = {bi, | 0<i<k-1}. As opposed to the construction
in Section [3.1]
Section for each set S € {A1, Az, Bi, Bg}, there are two corresponding sets of nodes of size
logk, denoted Fs = {f! | 0 < h < logk — 1} and Ts = {t | 0 < h < logk — 1}. For each
he {0, ...,logk — 1} and @ € {1,2}, the nodes (f4,.04,, £6, th.) constitute a 4-cycle. Each
node sj in a set S € {Aj, Ao, By, Bg} is connected by to all nodes in bin(s;). Up to here, the
construction differs from the construction in Section only by not having edges inside the
sets Ai, Ao, By, Bo.

We now add the following two gadgets to the graph.

the nodes of these sets are not connected to one another. In addition, as in

1. We add three nodes Cc , ci, C? connected as a triangle, another set of three nodes CP , Ch, Cc
connected as a triangle, and edges connecting on to Cc} for each i 4 j € {0,1,2}. We
connect all the nodes of the form fh th, h € {0,...,logk—1}, to Cl. Similarly, we

8
/n/nconnect all the nodes fh th, to Ch, the nodes fh, th, to C2 and the nodes thy th, to
C2.

2. For each set S € Aj, Ao, Bi, Bo, we add two sets of nodes, S = {3} | sh € st and § =
{5, | s) € S}. For each £€ oe and i € {0,...,4— 1} we connect a path (sp, 8%, 87), and

or each ¢ € {1,2} andi {0,...,n — 2}, we connect 5} to 5y*7.

In addition, we connect the gadgets by the edges:

a) (C2, a4) and (C}, a4), for each i € {0,...,& — 1}; (C2, a9) and (C2, af).

(
(

and

) and (Cy
b) (C?,b4) and ( CH, bi), for each i € {0,...,k — 1}; (CP, 62) and (C2, 08-1).
) and (Cy

(c) (C}, a, 2 ai), for each i € {0,...,k — 1}; (C2, a9) and (Cl, ak").

(d) (C}, 64) and (C?, bi), for each ¢ € {0,...,k — 1}; (C1, 08) and (C}, bE}.

Assume there is a proper 3-coloring of G. Denote by co,c1 and cz the colors of C®, C} and
C? respectively. By construction, these are also the colors of cP ; Ch and Cc, respectively. For
the nodes appearing in Section [3.1] coloring a node by co is analogous to not including it in the
vertex cover.

Claim 3. In each set S € {A), Ag, Bi, Bo}, at least one node is colored by co.

Proof. We start by proving the claim for S = A;. Assume, towards a contradiction, that all
nodes of A; are colored by c; and cz. All these nodes are connected to C?, so they must all be
colored by c;. Hence, all the nodes ai, i € {0,...,k — 1}, are colored by cp and cy. The nodes
ai, ie {0,...,k—1}, are connected to Cl, so they are colored by co and c as well.

Hence, we have a path (a), a9, at, at,...a*-1,ak-1) with an even number of nodes, starting
in a? and ending in at . This path must be colored by alternating cp and cz, but both a? anc
ak! are connected to C2, so they cannot be colored by c2, a contradiction.

A similar proof shows the claim for S = B). For S € {A2, By}, we use a similar argument

but change the roles of c, and co.

Claim 4. For each i € {0,...,k—1}, the node ai is colored by co iff bi is colored by co and
the node at, is colored by co iff bi, is colored by co.

Proof. Assume ai is colored by co, so all of its adjacent nodes bin(ai) can only be colored by
cy, or cg. As all of these nodes are connected to Cf, they must be colored by cz. Similarly, if a
node b in B, is colored by co, then the nodes bin(b?), which are also adjacent to Ch, must be
colored by c2.

Ifi #7 then there must be a bit 7 such that i, 4 j,, and there must be a pair of neighboring
nodes (f4,.t,) or (th, fb.) which are colored by cg. Thus, the only option is i = j. By
Claim 3] there is a node in B, that is colored by co, and so it must be bi.

An analogous argument shows that if bf is colored by co, then so does aj. For aj and 5,
similar arguments apply, where c; plays the role of c9.

Adding edges corresponding to the strings x and y: Given two bit strings x,y € {0, yy,
we augment the graph G described above with additional edges, which defines Gz.

Assume «x and y are indexed by pairs of the form (7, j) € {0,...,k— uy’. To construct Gz,y,
add edges to G by the following rules: if x;,; = 0 then add the edge (aj, a 3), and if y;,; = 0
then add the edge (bj, bi). To prove that {Gz,,} is a family of lower bound graphs, it remains
to prove the next lemma.

Lemma 2. The graph Gz is 3-colorable iff DISJ(x,y) = FALSE.
/n/nProof. For the first direction, assume Gz is 3-colorable, and denote the colors by co, ci and
c2, as before. By Claim [3} there are nodes ai € A; and a € Ag that are both colored by co.
Hence, the edge (ai, ad) does not exist in Gz, implying x;,; = 1. By Claim|d| the nodes bi and
bs are also colored co, so yi; = 1 as well, giving that DISJ(x,y) = FALSE, as needed.

For the other direction, assume DISJ(x, y) = FALSE, i.e, there is an index (i, 7) € {0,...,k — 1h
such that 2;,; = yi; = 1. Consider the following coloring.

1. Color Ci and C} by cj, for i € {0,1, 2}.

2. Color the nodes ai, bi, a and bi by co. Color the nodes ai’ and bi’, for i! # i, by c1, and
the nodes a, and by , for j’ 4 j, by ce.

3. Color the nodes of bin(a}) by ca, and similarly color the nodes of bin(bi) by ca. Color
the rest of the nodes in this gadget, i.e. bin(at~*) and bin(b¥~"), by co. Similarly, color

bin(a}) and bin(b}) by co and bin(ak? ) and bin(by 4 ) by ec.
4. Finally, color the nodes of the forms 5} and 5 as follows.
(a) Color a} and 64 by c1, all nodes @' and bi’ with i’ <i by co, and all nodes ai and bi
with i! > 7% by co.
(b Similarly, color a4 and bi, by ca, all nodes a and b} with i’ < i by co, and all nodes
a, and b5 with i’ >i by c.
(c) Color all nodes ai and bY with i! < i by cg, and all nodes a’ and bY with i! >i by
co.

(d) Similarly, color all nodes @ and by with i! <i by cy, and all nodes @ and bY with
Ss
u >t by co.

It is not hard to verify that the suggested coloring is indeed a proper 3-coloring of Gz, which
completes the proof.

Having constructed the family of lower bound graphs, we are now ready to prove Theorem [4]

Proof of Theorem To complete the proof of Theorem [4] we divide the nodes of G (which
are also the nodes of G,,,) into two sets. Let V4 = A,UAgUF'4,UT4, UF 4, UT 4,U {C8, ch, C2}U
A, U A, U Ag U Ag, and Vg = V \ Va. Note that n € @(k).

The edges in the cut E(V4, Vg) are the 6 edges connecting {C?,C},C2} and {C},C}, CF},
and 2 edges for every 4-cycle of the nodes of F4, UT4, U Fp, UTp, and F4, UT4, UF, UTp,, for
a total of O(logn) edges. Since Lemma [2] shows that {Gz} is a family of lower bound graphs
with respect to DISJx, K = k? € @(n?) and the predicate y < 3, we can apply Theorem [1] on
the above partition to deduce that any algorithm in the CONGEST model for deciding whether
a given graph is 3-colorable requires at least Q(n?/ log? n) rounds.

Any algorithm that computes x of the input graph, or produces a y-coloring of it, may be
sed to deciding whether y < 3, in at most O(D) additional rounds. Thus, the lower bound
applies to these problems as well.

Our construction and proof naturally extend to handle c-coloring, for any c > 3. To this
end, we add to G (and to Gz,,) new nodes denoted Clie {3,...,c— 1}, and connect them to
all of V4, and new nodes denoted Ci, i€ {3,...,c—1}, and connect them to all of Vg and also
to C2,C! and C?. The nodes C? are added to Vi, and the rest are added to Vj, which increases
the cut size by O(c) edges.

Assume the extended graph is colorable by c colors, and denote by c; the color of the
node C% (these nodes are connected by a clique, so their colors are distinct). The nodes Ci,
€ {2,...,¢—1} form a clique, and they are all connected to the nodes C®,C! and C?, so
1ey are colored by the colors {c3,...,¢e—1}, in some order. All the original nodes of V4 are

co

ct

10
/n/nconnected to Ci, i € {3,...,¢—1}, and all the original nodes of Vg are connected to Ci,
i€ {3,...,¢— 1}, so the original graph must be colored by 3 colors, which we know is possible
iff DISJ(x, y) = FALSE.

We added 2c — 6 nodes to the graph, so the inputs strings are of length K = n — 2c+ 6.
Thus, the new graphs constitute a family of lower bound graphs with respect to EQ, and the
predicate y < c, the communication complexity of EQ; is in Q(K?) = Q((n—c)?), the cut size
is O(c + logn), and Theorem [I] completes the proof.

A lower bound for (4/3 — €)-approximation: Finally, we extend our construction to give a
lower bound for approximate coloring. That is, we show a similar lower bound for computing a
(4/3 — €)-approximation to y and for finding a coloring in (4/3 — €)x colors.

Observe that since x is integral, any (4/3 — €)-approximation algorithm must return the
exact solution in case y = 3. Thus, in order to rule out the possibility for an algorithm which
is allowed to return a (4/3 — €)-approximation which is not the exact solution, we need a more
general construction. For any integer c, we show a lower bound for distinguishing between the
case x < 3c and y > 4c.

Claim 5. Given an integer c, any distributed algorithm in the CONGEST model that distin-
guishes a graph G with x(G) < 3c from a graph with y(G) > 4e requires Q(n?/(c3 log? n))
rounds.

To prove Claim [5] we show a family of lower bound graphs with respect to the DISJx

function, where K € ©@(n?/c?), and the predicate y < 3c (TRUE) or y > 4c (FALSE). The
predicate is not defined for other values of y.
We create a graph G{,, composed of ¢ copies of Gz,y. The i-th copy is denoted G,,,(¢),
and its nodes are partitioned into V4(z) and Vg(i). We connect all the nodes of V4(i) to all
nodes of V4(j), for each i 4 j. Similarly, we connect all the nodes of Vg(i) to all the nodes of
Vp(j). This construction guarantees that each copy is colored by different colors, and hence if
DISJ(az,y) = FALSE then x(G¢,,) = 3c and otherwise y(G{,,) > 3c. Therefore, G{., is a family
of lower bound graphs.

Proof of Claim [5} Note that n € O(kc). Thus, K = |2| = |y| = n?/c?. Furthermore,
observe that for each G,y(i), there are O(logn) edges in the cut, so in total G‘,,, contains
O(clogn) edges in the cut. Since we showed that Gey is a family of lower bound graphs,
we can apply Theorem [I] to deduce that because of the lower bound for Set Disjointness, any
algorithm in the CONGEST model for distinguishing between y < 3c and x > 4c requires at
least. 2.(n?/c3 log?(n)) rounds.

For any € > 0 and any c it holds that (4/3 — €)3c < 4c. Thus, we can choose c to be an
arbitrary constant to achieve the following theorem.

Theorem 5. For any constant ¢ > 0, any distributed algorithm in the CONGEST model that
computes a (4/3 — €)-approximation to x requires Q(n?/ log? n) rounds.

4 Quadratic and Near-Quadratic Lower Bounds for Problems
in P

In this section we support our claim that what makes problems hard for the CONGEST model is
not necessarily them being NP-hard problems. First, we address a class of subgraph detection
problems, which requires detecting cycles of length 8 and a given weight, and show a near-
quadratic lower bound on the number of rounds required for solving it, although its sequential
complexity is polynomial. Then, we define a problem which we call the Identical Subgraphs

11
/n/nFigure 3: The family of lower bound graphs for detecting weighted cycles, with many edges omitted
for clarity. Here, xo, = 1 and yx—-i4—-1 = 1. Thus, at is connected to as by an edge of weight
k3+k-04+1 = k3+1, and bk is connected to bk! by an edge of weight k?—(k(k—1)+k—1) = k?—k?-+41.
All the dashed edges are of weight 0.

Detection problem, in which the goal is to decide whether two given subgraphs are identical.
While this last problem is rather artificial, it allows us to obtain a strictly quadratic lower bound
for the CONGEST model, with a problem that requires only a single-bit output.

4.1 Weighted Cycle Detection

In this section we show a lower bound on the number of rounds needed in order to decide the
graph contains a cycle of length 8 and weight W, such that W is a polylog(n)-bit value given
as an input. Note that this problem can be solved easily in polynomial time in the sequential
setting by simply checking all of the at most (3) cycles of length 8.

Theorem 6. Any distributed algorithm in the CONGEST model that decides if a graph with edge
weights w : E — [0, poly(n)] contains a cycle of length 8 and weight W requires Q(n?/ log? n)
rounds.

Similarly to the previous sections, to prove Theorem [6] we describe a family of lower bound
graphs with respect to the Set Disjointness function and the predicate P that says that the
graph contains a cycle of length 8 and weight W.

The fixed graph construction: The fixed graph construction G = (V, E) is defined as follows.
The set of nodes contains four sets A;, Ag, By, and Bg, each of size k. To simplify our proofs in
this section, we assume that k > 3. For each set S' € {Aj, Ao, Bi, Bo} there is a node cg, which
is connected to each of the nodes in S by an edge of weight 0. In addition there is an edge
between c4, and cp, of weight 0 and an edge between c4, and cg, of weight 0 (see Figure [3).

Adding edges corresponding to the strings « and y: Given two binary strings x,y €
{0, ye”, we augment the fixed graph G defined in the previous section with additional edges,
which defines Gz. Recall that we assume that k > 3. Let x and y be indexed by pairs of
the form (i,j) € {0,...,k-— 1p. For each (i,j) € {0,...,k— 1}, we add to Gy the following
edges. If x;,; = 1, then we add an edge of weight k3 + ki + j between the nodes ai and ai. If
Yi = 1, then we add an edge of weight k3 — (ki + j) between the nodes bi and bh. We denote
by InputEdges the set of edges {(u,v) | we Ar Av € Ag} U{(u,v) | we Bi Av € Bo}, and we
denote by w(u,v) the weight of the edge (u,v).

12
/n/nObserve that the graph does not contain edges of negative weight. Furthermore, the weight
of any edge in InputEdges does not exceed k® + k? — 1, which is the weight of the edge
(ak om ay), in case rz_1,4-1 = 1. Similarly, the weight of an edge in InputEdges is not less
than k® — k? +1, which is the weight of the edge (oft, bf), in case yp_1,4-1 = 1. Using these

two simple observations, we deduce the following claim.

Claim 6. For any cycle of weight 2k*, the number of edges it contains that are in InputEdges
is exactly two.

Proof. Let C be a cycle of weight 2k?, and assume for the sake of contradiction that C’ does
not contain exactly two edges from InputEdges. In case C contains exactly one edge from
InputEdges, then the weight of C is at most k? + k? — 1 < 2k, because all the other edges
of C are of weight 0. Otherwise, in case C contains three or more edges from InputEdges, it
holds that the weight of C is at least 3k° — 3k? + 3 > 2k?, because all the other edges on C' are
of non-negative weight.

To prove that {Gz,} satisfies the definition of a family of lower bound graphs, we prove the
following lemma.

Lemma 3. The graph Gz, contains a cycle of length 8 and weight W = 2k? if and only if
DISJ(x, y) = FALSE.

Proof. For the first direction, assume that DISJ(x,y) = FALSE and let 0 < i,j < k—1 be such
that vj; = 1 and y;,; = 1. Consider the cycle (ai, CA,>CBy> bi, bb, CBs CAgs a). It is easy to verify
that this is a cycle of length 8 and weight w(a}, a5) + w(b},b3) =k +kitj+k?—ki-j = 2k,
as needed.
For the other direction, assume that the graph contains a cycle C of length 8 and weight 2k?.
By Claim|6| C contains exactly two edges from InputEdges. Denote these two edges by (w1, v1)
and (ug, v2). Since all the other edges in C are of weight 0, the weight of C is w(u1, v1)+w(ug, v2).
The rest of the proof is by case analysis, as follows. First, it is not possible that (wz, v1), (ua, v2) €
{(u,v) | uw € AiAv € Ap}, since in this case w(u1, v1)+-w(ua, v2) > w(a?,a9)+w(al, ad) = 2k3+1.
Similarly, it is not possible that (wu, v1), (ue, v2) € {(u,v) | u € By Av € Bo}, since in this case
w(ur, v1) +w(ug, v2) ; w(d9, 8) +w(d9, bd) = 2k3-1. ar suppose without loss of generality
that (ui, 1) ye XK u,v) |ue ArAv € Ag} and (u2,v2) € {(u,v) | we By Av € Bo}. Denote
ul =a),u2 = a, vp = bi and vg = bh. It holds that w(ai, a)) + w(bi, oh ) = 2k3 if and only i
i=7 and j = j’, which implies that 2;,; = 1 and y;,; = 1 and DISJ(«,y) = FALSE.

Having constructed the family of lower bound graphs, we are now ready to prove Theorem|[6]

Proof of Theorem [6} To complete the proof of Theorem [6] we divide the nodes of G (which
are also the nodes of Gz,y) into two sets. Let V4 = A; U Ao U {c4,,¢4,} and Vg = V \ Va.
Note that n € @(k). Thus, K = |z| = |y| = O(n”). Furthermore, note that the only edges in
the cut E(V4,Vg) are the edges (c4,,¢p,) and (c4,,cp,). Since Lemma [3] shows that {Gry}
is a family of lower bound graphs, we apply Theorem []] on the above partition to deduce that
because of the lower bound for Set Disjointness, any algorithm in the CONGEST model for
deciding whether a given graph contains a cycle of length 8 and weight W = 2k? requires at
least Q(K/logn) = Q(n?/log n) rounds.

4.2 Identical Subgraphs Detection

In this section we show the strongest possible, quadratic lower bound, for a problem which can
be solved in linear time in the sequential setting.
Consider the following sequential specification of a graph problem.

13
/n/nDefinition 2. (The Identical Subgraphs Detection Problem)

Given a weighted input graph G = (V,E,w), with an edge-weight function w : E > {0,...,W — 1},
W € polyn, such that the set of nodes V is partitioned into two enumerated sets of the same
size, V4 = {ao,...,ax_1} and Vg = {bo,..., bh-1}, the Identical Subgraphs Detection problem is
to determine whether the subgraph induced by the set V4 is identical to the subgraph induced by
the set Vp, in the sense that for each 0 < i,j < k—1 it holds that (a;,a;) € E if and only if

(bi, bj) € E and w(aji, aj) = w(bi,b;) if these edges exist.

The identical subgraphs detection problem can be solved easily in linear time in the se-
quential setting by a single pass over the set of edges. However, as we prove next, it requires
a quadratic number of rounds in the CONGEST model, in any deterministic solution (note
that this restriction did not apply in the previous sections). For clarity, we emphasize that in
the distributed setting, the input to each node in the identical subgraphs detection problem is
its enumeration a; or b;, as well as the enumerations of its neighbors and the weights of the
respective edges. The outputs of all nodes should be TRUE if the subgraphs are identical, and
FALSE otherwise.

Theorem 7. Any distributed deterministic algorithm in the CONGEST model for solving the
identical subgraphs detection problem requires Q(n?) rounds.

To prove Theorem [7] we describe a family of lower bound graphs.

The fixed graph construction: The fixed graph G is composed of two k-node cliques on the
node sets V4 = {ao,...,@,-1} and Vg = {bo,...,bg-1}, and one extra edge (ap, bo).

Adding edge weights corresponding to the strings x and y: Given two binary strings x
and y, each of size K = (5) logn, we augment the graph G' with additional edge weights, which
define G,. For simplicity, assume that x and y are vectors of log n-bit numbers each having
(5) entries enumerated as and yij, with i < j, i,j € {0,...,k—1}. For each such i and j
we set the weights of w(a;,a;) = x; and w(b;,bj;) = yi,j, and we set w(ag, bo) = 0. Note that
{Gz,y} is a family of lower bound graphs with respect to EQ, and the predicate P that says
that the subgraphs are identical in the aforemention sense.

Proof of Theorem [7 Note that n € O(k), and thus K = |a| = |y| = O(n? logn). Further-
more, the only edge in the cut E(V4,Vg) is the edge (ao, bo). Since we showed that {Gz}
is a family of lower bound graphs, we can apply Theorem |1]on the above partition to deduce
that because of the lower bound for EQ;,, any deterministic algorithm in the CONGEST mode
for solving the identical subgraphs detection problem requires at least Q(K/logn) = O(n?)

rounds.

We remark that in a distributed algorithm for the identical subgraphs detection problem
running on our family of lower bound graphs, information about essentially all the edges anc
weights in the subgraphs induced on V4 and Vg needs to be sent across the edge (ao, bo). This
might raise the suspicion that this problem is reducible to learning the entire graph, making
the lower bound trivial. To argue that this is far from being the case, we present a randomizec
algorithm that solves the identical subgraphs detection problem in O(D) rounds and succeeds
w.h.p. This has the additional benefit of providing the strongest possible separation between
deterministic and randomized complexities for global problems in the CONGEST model, as the
former is Q(n?) and the latter is at most O(D).

Our starting point is the following randomized algorithm for the EQ, problem, presented
in Exersise 3.6]. Alice chooses a prime number p among the first K 2 primes uniformly at
random. She treats her input string x as a binary representation of an integer % = ye 2x0,
and sends p and & (mod p) to Bob. Bob similarly computes y, compares Z mod p with y mod p,

14
/n/nand returns TRUE if they are equal and false otherwise. The error probability of this protocol is
at most 1/K.

We present a simple adaptation of this algorithm for the identical subgraph detection prob-
lem. Consider the following encoding of a weighted induced subgraph on V4: for each pair 7, 7
of indices, we have [log W] + 1 bits, indicating the existence of the edge and its weight (recall
that W € polyn is an upper bound on the edge weights). This weighted induced subgraph
is thus represented by a K € O(n? logn) bit-string, denoted x = xo,...,@K_1, and each pair
(i,j) has a set Sj; of indices representing the edge (a;,a;). Note that the bits {x | ¢ € s;,;} are
known to both a; and a;, and in the algorithm we use the node with smaller index in order to
encode these bits. Similarly, a K € O(n? logn) bit-string, denoted y = yo,...,yK—1 encodes a
weighted induced subgraph on Vg.

The Algorithm. As standard, assume the input graph is connected. The nodes are
enumerated as in Definition [2] The algorithm starts with some node, say, ag, constructing a
BFS tree, which completes in O(D) rounds. Then, ao chooses a prime number p among the
first K? primes uniformly at random and sends p to all the nodes over the tree, which takes
O(D) rounds.

Each node a; computes the sum >> joi ee Sij x2’ mod p, and the nodes then aggregate
these local sums modulo p up the tree, until ag computes the sum Z mod p= > ji > l€5;,j apr!
mod p. A similar procedure is then invoked w.r.t y. Finally, ag compares Z mod p and y
mod p, and downcasts over the BFS tree its output, which is TRUE if these values are equal and
is FALSE otherwise.

If the subgraphs are identical, ag always returns TRUE, while otherwise their encoding differs

in at least one bit, and as in the case of EQ, ag returns TRUE falsely with probability at most
1/K € O(1/n?).

Theorem 8. There is a randomized algorithm in the CONGEST model that solves the identical
subgraphs detection problem on any connected graph in O(D) rounds.

5 Weighted APSP

In this section we use the following, natural extension of Definition |1| in order to address more
general 2-party functions, as well as distributed problems that are not decision problems.

For a function f : {0,1}*" x {0,1}%? > {0,1}”" x {0,1}%*, we define a family of lower
bound graphs in a similar way as Definition [I] except that we replace item (4) in the definition
with a generalized requirement that says that for G,,,, the values of the of nodes in V4 uniquely
determine the left-hand side of f(x,y), and the values of the of nodes in Vg determine the
right-hand side of f(x,y). Next, we argue that theorem similar to Theorem }1| holds for this
case.

Theorem 9. Fix a function f : {0, yy x {0, ye — {0, ye x {0, iy and a graph problem
P. If there is a family {Gz} of lower bound graphs with C = E(Va, Vg) then any deterministic
algorithm for solving P in the CONGEST model requires Q(CC(f)/|C|logn) rounds, and any
randomized algorithm for deciding P in the CONGEST model requires Q(CC®(f)/|C| log n)
rounds.

The proof is similar to that of Theorem Notice that the only difference between the
theorems, apart from the sizes of the inputs and outputs of f, are with respect to item (4) in
the definition of a family of lower bound graphs. However, the essence of this condition remains
the same and is all that is required by the proof: the values that a solution to P assigns to nodes
in V4 determines the output of Alice for f(x,y), and the values that a solution to P assigns to
nodes in Vg determines the output of Bob for f(a, y).

15
/n/n5.1 A Linear Lower Bound for Weighted APSP

Nanongkai showed that any algorithm in the CONGEST model for computing a poly(n)-
approximation for weighted all pairs shortest paths (APSP) requires at least Q(n/ log n) rounds.
In this section we show that a slight modification to this construction yields an Q(n) lower bound
for computing exact weighted APSP. As explained in the introduction, this gives a separation
between the complexities of the weighted and unweighted versions of APSP. At a high level,
while we use the same simple topology for our lower bound as in [56], the reason that we are
able to shave off the extra logarithmic factor is because our construction uses O(log n) bits for
encoding the weight of each edge out of many optional weights, while in only a single bit is
used per edge for encoding one of only two options for its weight.

Theorem 10. Any distributed algorithm in the CONGEST model for computing exact weighted
all pairs shortest paths requires at least Q(n) rounds.

The reduction is from the following, perhaps simplest, 2-party communication problem.
Alice has an input string x of size kK and Bob needs to learn the string of Alice. Any algorithm
possibly randomized) for solving this problem requires at least Q(A) bits of communication,
oy a trivial information theoretic argument.

Notice that the problem of having Bob learn Alice’s input is not a binary function as
addressed in Section Similarly, computing weighted APSP is not a decision problem, but
rather a problem whose solution assigns a value to each node (which is its vector of distances
rom all other nodes). We therefore use the extended Theorem [J] above.

The fixed graph construction: The fixed graph construction G = (V,E) is defined as
ollows. It contains a set of n — 2 nodes, denoted A = {ao,...,@n—3}, which are all connected to
an additional node a. The node a is connected to the last node b, by an edge of weight 0.

Adding edge weights corresponding to the string x: Given the binary string x of size
K = (n—2)logn we augment the graph G with edge weights, which defines G, by having each
non-overlapping batch of log n bits encode a weight of an edge from A to a. It is straightforward
to see that G; is a family of lower bound graphs for a function f where Ky = L; = 0, since
the weights of the edges determine the right-hand side of the output (while the left-hand side
is empty).

Proof of Theorem To prove Theorem |10} we let V4 = AU{a} and Vg = {b}. Note that
K = || = O(nlogn). Furthermore, note that the only edge in the cut E(V4, Vg) is the edge
(a,b). Since we showed that {G,} is a family of lower bound graphs, we apply Theorem [J] on
the above partition to deduce that because Kk bits are required to be communicated in order
for Bob to know Alice’s K-bit input, any algorithm in the CONGEST model for computing
weighted APSP requires at least Q(K/ log n) = Q(n) rounds.

5.2 The Alice-Bob Framework Cannot Give a Super-Linear Lower Bound
for Weighted APSP

In this section we argue that a reduction from any 2-party function with a constant partition
of the graph into Alice and Bob’s sides is provable incapable of providing a super-linear lower
bound for computing weighted all pairs shortest paths in the CONGEST model. A more
detailed inspection of our analysis shows a stronger claim: our claim also holds for algorithms
for the CONGEST-BROADCAST model, where in each round each node must send the same
(log n)-bit message to all of its neighbors. The following theorem states our claim.

Theorem 11. Let f : {0, yy x {0, 12 — {0, yh x {0, 1} be a function and let Gry
be a family of lower bound graphs w.r.t. f and the weighted APSP problem. When applying

16
/n/nTheorem [9 to f and Gry, the lower bound obtained for the number of rounds for computing
weighted APSP is at most linear in n.

Roughly speaking, we show that given an input graph G = (V,£) and a partition of the
set of vertices into two sets V = V4 U Vg, such that the graph induced by the nodes in V4 is
simulated by Alice and the graph induced by nodes in Vg is simulated by Bob, Alice and Bob
can compute weighted all pairs shortest paths by communicating O(n log n) bits of information
for each node touching the cut C = (V4,Vg) induced by the partition. This means that for
any 2-party function f and any family of lower bound graphs w.r.t. f and weighted APSP
according to the extended definition of Section [5.1] since Alice and Bob can compute weighted
APSP which determines their output for f by exchanging only O(|V(C)|nlogn) bits, where
V(C) is the set of nodes touching C, the value CC(f) is at most O(|V(C)|nlogn). But then
the lower bound obtained by Theorem |9] cannot be better than Q(n), and hence no super-linear
lower can be deduced by this framework as is.

Formally, given a graph G = (V = V4UVp, E) we denote C = E(V4,Vg). Let V(C) denote
the nodes touching the cut C, with C4 = V(C)N V4 and Cg = V(C)NVzg. Let Ga = (Va, Ea)
be the subgraph induced by the nodes in V4 and let Gg = (Vz, Ep) be the subgraph induced
by the nodes in Vg. For a graph H, we denote the weighted distance between two nodes u,v
by wdist (u,v).

Lemma 4. Let G = (V = V4UVz, E,w) be a graph with an edge-weight function w: E >
{1,...,W}, such that W € poly n. Suppose that G4, Cg, C and the values of w on E, and C
are given as input to Alice, and that Gg, C4, C and the values of w on Eg and C are given as
input to Bob.

Then, Alice can compute the distances in G from all nodes in V4 to all nodes in V and Bob
can compute the distances from all nodes in Vg to all the nodes in V, using O(|V(C)|nlogn)
bits of communication.

Proof. We describe a protocol for the required computation, as follows. For each node u € Cp,
Bob sends to Alice the weighted distances in Gg from wu to all nodes in Vg, that is, Bob
sends {wdistg,(u,v) | uw € Cg,v € Vg} (or o for pairs of nodes not connected in Gg).
Alice constructs a virtual graph G’y = (V4, E',,w',) with the nodes V4 = V4 U Cg and edges
E', = E,xUCU (Cg x Cg). The edge-weight function w’, is defined by w',(e) = w(e) for each
e € EaUC, and w',(u,v) for u,v € Cg is defined to be the weighted distance between u and
v in Gg, as received from Bob. Alice then computes the set of all weighted distances in G',,
{wdista, (u,v) | u,v € Va}.

Alice assigns her output for the weighted distances in G as follows. For two nodes u,v €
V4 UCg, Alice outputs their weighted distance in G’,, wdistg, (u, v). For a node u € V4 and a
node v € Vg \ Cz, Alice outputs min{wdistg, (u, x) + wdiste, (x, v) | x € Cp}, where wdistgy,
is the distance in G’, as computed by Alice, and wdistg, is the distance in Gg that was sent
by Bob.

For Bob to compute his required weighted distances, for each node u € C'4, similar informa-
tion is sent by Alice to Bob, that is, Alice sends to Bob the weighted distances in G4 from u to
all nodes in V4. Bob constructs the analogous graph G’, and outputs his required distance. The
next paragraph formalizes this for completeness, but may be skipped by a convinced reader.

Formally, Alice sends {wdistg, (u,v) | u€ C4,v € Va}. Bob constructs Gg = (Vp, E’y, wp)
with VZ = VgUCy and edges Ep = Eg UCU(C4 x C4). The edge-weight function w'p is defined
by w,(e) = w(e) for each e € Eg UC, and w'p(u, v) for u,v € Ca is defined to be the weighted
distance between u and v in G‘4, as received from Alice (or oo if they are not connected in G4).
Bob then computes the set of all weighted distances in G'p, {wdistq, (u,v) | u,v © Vg}. Bob
assigns his output for the weighted distances in G as follows. For two nodes u,v € Vg UCa,
Bob outputs their weighted distance in Gg, wdistq,(u,v). For a node u € Vp and a node

17
/n/nv € Va \ Ca, Bob outputs min{wdistg, (u, x) + wdistg,(x,v) | « € Ca}, where wdistq, is the
distance in G‘, as computed by Bob, and wdistg, is the distance in G4 that was sent by Alice.

Complexity. Bob sends to Alice the distances from all nodes in Cg to all node in Vg, which
takes O(|C'p| |Va| log n) bits, and similarly Alice sends O(|C'4| |V4| log n) bits to Bob, for a total
of O({V(C)| n log n) bits.

Correctness. By construction, for every edge (u,v) € CgxCg in G', with weight wdistey, (u,v),
there is a corresponding shortest path P,,, of the same weight in Gg. Hence, for any path
P' = (v9, U1,---, 0%) in G4, between vo, uz € V4, there is a corresponding path Py, ., of the same
weight in G, where P is obtained from P’ by replacing every two consecutive nodes v;, vj41 in
PN Cz by the path Py,v,,,- Thus, wdistey, (v0, UR) > wdistc(vo, UE).

On the other hand, for any shortest path P = (vo,v1,...,U%) in G connecting vo, vu, € V4,
there is a corresponding path P’ of the same weight in G’,, where P’ is obtained from P by
replacing any sub-path (v;,...,v;) of P contained in Gg and connecting v;,vj € Cg by the
edge (v;, vj) in Gy. Thus, wdistg(vo, vz) > wiistg, (vo, Uk). Alice thus correctly computes the
weighted distances between pairs of nodes in V4.

It remains to argue about the weighted distances that Alice computes to nodes in Vg \ Cp.
Any lightest path P in G connecting a node u € V4 and a nodev € Vg\Cg must cross at least one
edge of C and thus must contain a node in Cg. Therefore, wdistg(u, v) = min{wdistg(u, x) 4
wdista(x,v) | x € Cp}. Recall that we have shown that wdistg,(u,x) = wdistg(u,x) for any
u,x € V4. The sub-path of P connecting x and v is a shortest path between these nodes, anc
is contained in Gg, so wdistg,(x,v) = wdistg(x,v). Hence, the distance min{wdistq (u,x) +
wdistg,(x,v) |  € Cg} returned by Alice is indeed equal to wdistg(u, v).

The outputs of Bob are correct by the analogous arguments, completing the proof.

Proof of Theorem [Ti} Let f : {0,1}* x {0,1}*? > {0,1}” x {0, 1} be a function and le
Gzy be a family of lower bound graphs w.r.t. f and the weighted APSP problem. By Lemmaf4j
Alice and Bob can compute the weighted distances for any graph in Gz, by exchanging at mos
O(|V(C)|nlogn) bits, which is at most O(|C|nlogn) bits. Since Gey is a family of lower
bound graphs w.r.t. f and weighted APSP, condition (4) gives that this number of bits is an
upper bound for CC(f). Therefore, when applying Theorem [] to f and Gz, the lower bounc
obtained for the number of rounds for computing weighted APSP is Q(CC(f)/|C| log n), which
is no higher than a bound of Q(n).

Extending to ¢ players: We argue that generalizing the Alice-Bob framework to a shared-
blackboard multi-party setting is still insufficient for providing a super-linear lower bound for
weighted APSP. Suppose that we increase the number of players in the above framework to t
players, Po,...,P:-1, each simulating the nodes in a set V; in a partition of V in a family o
lower bound graphs w.r.t. a t-party function f and weighted APSP. That is, the outputs o
nodes in V; for an algorithm ALG for solving a problem P in the CONGEST model, uniquely
determines the output of player P; in the function f. The function f is now a function from
{0,1} x --- x {0,1} 4-1 to {0,1}4° x --- x {0, 141.

The communication complexity CC(f) is the total number of bits written on the sharec
blackboard by all players. Denote by C' the set of cut edges, that is, the edge whose end-
points do not belong to the same V;. Then, if ALG is a R-rounds algorithm, we have tha
writing O(R|C|logn) bits on the shared blackboard suffice for computing f, and so R =
Q(CC(f)/|C| log n).

We now consider the problem P to be weighted APSP. Let f be a t-party function anc
let Gxo,....2,-, be a family of lower bound graphs w.r.t. f and weighted APSP. We first have
the players write all the edges in C on the shared blackboard, for a total of O(|C|logn) bits.

18
/n/nThen, in turn, each player P; writes the weighted distances from all nodes in V; to all nodes in
V(C)NV;. This requires no more than O(|V (C)|n log n) bits.

It is easy to verify that every player P; can now compute the weighted distances from all
nodes in V; to all nodes in V, in a manner that is similar to that of Lemma |4]

This gives an upper bound on CC(f), which implies that any lower bound obtained by a re-
duction from f is Q(CC(f)/|C| log n), which is no larger than 9((|V(C)|n+|C|) log n/|C| log n),
which is no larger than ((n), since |V(C)| < 2/C].

Remark 1: Notice that the t-party simulation of the algorithm for the CONGEST model does
not require a shared blackboard and can be done in the peer-to-peer multiparty setting as well,
since simulating the delivery of a message does not require the message to be known globally.
This raises the question of why would one consider a reduction to the CONGEST model from
the stronger shared-blackboard model to begin with. Notice that our argument above for t
players does not translate to the peer-to-peer multiparty setting, because it assumes that the
edges of the cut C can be made global knowledge within writing |C| log n bits on the blackboard.
However, what our extension above shows is that if there is a lower bound that is to be obtained
using a reduction from peer-to-peer t-party computation, it must use a function f that is strictly
harder to compute in the peer-to-peer setting compared with the shared-blackboard setting.

Remark 2: We suspect that a similar argument can be applied for the framework of non-fixed
Alice-Bob partitions (e.g., (64)), but this requires precisely defining this framework which is not
addressed in this version.

6 Discussion

This work provides the first super-linear lower bounds for the CONGEST model, raising a
plethora of open questions. First, we showed for some specific problems, namely, computing a
minimum vertex cover, a maximum independent set and a x-coloring, that they are nearly as
hard as possible for the CONGEST model. However, we know that approximate solutions for
some of these problems can be obtained much faster, in a polylogarithmic number of rounds or
even less. A family of specific open questions is then to characterize the exact trade-off between
approximation factors and round complexities for these problems.

Another specific open question is the complexity of weighted APSP, which has also been
asked in previous work (26]56). Our proof that the Alice-Bob framework is incapable of providing
super-linear lower bounds for this problem may be viewed as providing evidence that weighted
APSP can be solved much faster than is currently known. Together with the recent sub-
quadratic algorithm of 28}, this brings another angle to the question: can weighted APSP be
solved in linear time?

Finally, we propose a more general open question which addresses a possible classification of
complexities of global problems in the CONGEST model. Some such problems have complexities
of Q(D), such as constructing a BFS tree. Others have complexities of 0(D + Vn), such
as finding an MST. Some problems have near-linear complexities, such as unweighted APSP.
And now we know about the family of hardest problems for the CONGEST model, whose
complexities are near-quadratic. Do these complexities capture all possibilities, when natural
global graph problems are concerned? Or are there such problems with a complexity of, say,
O(n!+°), for some constant 0 < 5 < 1? A similar question was recently addressed in for

the LOCAL model, and we propose investigating the possibility that such a hierarchy exists for
the CONGEST model.

Acknowledgement: We thank Amir Abboud, Ohad Ben Baruch, Michael Elkin, Yuval Filmus
and Christoph Lenzen for useful discussions.

19
/n/nReferences

1

ot

ot

Amir Abboud, Keren Censor-Hillel, and Seri Khoury. Near-linear lower bounds for dis-
tributed distance computations, even in sparse networks. In Proceedings of the 30th Inter-
national Symposium on Distributed Computing, DISC, pages 29-42, 2016.

Amir Abboud and Kevin Lewi. Exact weight subgraphs and the k-sum conjecture. In Pro-
ceedings of the 40th International Colloquium on Automata, Languages, and Programming,
ICALP, Part I, pages 1-12, 2013.

Amir Abboud, Kevin Lewi, and Ryan Williams. Losing weight by gaining edges. In
Proceedings of the 22th Annual European Symposium on Algorithms, ESA, pages 1-12,
2014.

Noga Alon, Raphael Yuster, and Uri Zwick. Finding and counting given length cycles.
Algorithmica, 17(3):209-223, 1997.

Matti Astrand, Patrik Floréen, Valentin Polishchuk, Joel Rybicki, Jukka Suomela, and Jara
Uitto. A local 2-approximation algorithm for the vertex cover problem. In Proceedings of
the 28rd International Symposium on Distributed Computing, DISC, pages 191-205, 2009.

Matti Astrand and Jukka Suomela. Fast distributed approximation algorithms for vertex
cover and set cover in anonymous networks. In Proceedings of the 22nd Annual ACM
Symposium on Parallelism in Algorithms and Architectures, SPAA, pages 294-302, 2010.

Reuven Bar-Yehuda, Keren Censor-Hillel, Mohsen Ghaffari, and Gregory Schwartzman.
Distributed approximation of maximum independent set and maximum matching. In Pro-
ceedings of the ACM Symposium on Principles of Distributed Computing, PODC, 2017.

Reuven Bar-Yehuda, Keren Censor-Hillel, and Gregory Schwartzman. A distributed (2+¢)-
approximation for vertex cover in o(logd/e log log 6) rounds. In Proceedings of the 2016
ACM Symposium on Principles of Distributed Computing, PODC, pages 3-8, 2016.

Leonid Barenboim. On the locality of some np-complete problems. In Proceedings of the
89th International Colloquium on Automata, Languages, and Programming, ICALP, Part
II, pages 403-415, 2012.

Leonid Barenboim. Deterministic (A + 1)-coloring in sublinear (in A) time in static,
dynamic, and faulty networks. J. ACM, 63(5):47:1-47:22, 2016.

Leonid Barenboim and Michael Elkin. Deterministic distributed vertex coloring in poly-
logarithmic time. J. ACM, 58(5):23:1-23:25, 2011.

Leonid Barenboim and Michael Elkin. Combinatorial algorithms for distributed graph
coloring. Distributed Computing, 27(2):79-93, 2014.

Leonid Barenboim, Michael Elkin, and Fabian Kuhn. Distributed (delta+1)-coloring in
linear (in delta) time. SIAM J. Comput., 43(1):72-95, 2014.

Leonid Barenboim, Michael Elkin, Seth Pettie, and Johannes Schneider. The locality of
distributed symmetry breaking. J. ACM, 63(3):20:1-20:45, 2016.

Marijke H. L. Bodlaender, Magnts M. Hallddrsson, Christian Konrad, and Fabian Kuhn.
Brief announcement: Local independent set approximation. In Proceedings of the ACM
Symposium on Principles of Distributed Computing, PODC, pages 93-95, 2016.

20
/n/n16

17

18

19

20

21

22

23

24

29

30

31

Keren Censor-Hillel, Petteri Kaski, Janne H. Korhonen, Christoph Lenzen, Ami Paz, and
Jukka Suomela. Algebraic methods in the congested clique. In Proceedings of the 2015
ACM Symposium on Principles of Distributed Computing, PODC, 2015.

Keren Censor-Hillel, Telikepalli Kavitha, Ami Paz, and Amir Yehudayoff. Distributed con-
struction of purely additive spanners. In Proceedings of the 30th International Symposium
on Distributed Computing, DISC, pages 129-142, 2016.

Yi-Jun Chang, Tsvi Kopelowitz, and Seth Pettie. An exponential separation between
randomized and deterministic complexity in the LOCAL model. In Proceedings of the
IEEE 57th Annual Symposium on Foundations of Computer Science, FOCS, pages 615

624, 2016.

Yi-Jun Chang and Seth Pettie. A time hierarchy theorem for the LOCAL model. CoRR,
abs/1704.06297, 2017.

Kai-Min Chung, Seth Pettie, and Hsin-Hao Su. Distributed algorithms for the lovasz
local lemma and graph coloring. In Proceedings of the ACM Symposium on Principles of
Distributed Computing, PODC, pages 134-1438, 2014.

Richard Cole and Uzi Vishkin. Deterministic coin tossing with applications to optimal
parallel list ranking. Information and Control, 70(1):32-53, 1986.

Andrzej Czygrinow, Michal Hanckowiak, and Wojciech Wawrzyniak. Fast distributed ap-
proximations in planar graphs. In Proceedings of the 22nd International Symposium on
Distributed Computing, DISC, pages 78-92, 2008.

Seren Dahlgaard, Mathias Beek Tejs Knudsen, and Morten Stéckel. Finding even cycles
faster via capped k-walks. CoRR, abs/1703.10380, 2017.

Danny Dolev, Christoph Lenzen, and Shir Peled. tri, tri again”: Finding triangles and
small subgraphs in a distributed setting - (extended abstract). In Proceedings of the 26th
International Symposium on Distributed Computing, DISC, pages 195-209, 2012.

Andrew Drucker, Fabian Kuhn, and Rotem Oshman. On the power of the congested clique
model. In Proceedings of the 33rd ACM Symposium on Principles of Distributed Computing,
PODC, pages 367-376, 2014.

Michael Elkin. Distributed approximation: a survey. SIGACT News, 35(4):40-57, 2004.

Michael Elkin. An unconditional lower bound on the time-approximation trade-off for the
distributed minimum spanning tree problem. SIAM J. Comput., 36(2):433-456, 2006.

Michael Elkin. Distributed exact shortest paths in sublinear time. CoRR, abs/1703.01939,
2017.

Yuval Emek, Christoph Pfister, Jochen Seidel, and Roger Wattenhofer. Anonymous net-
works: randomization = 2-hop coloring. In Proceedings of the ACM Symposium on Prin-
ciples of Distributed Computing, PODC, pages 96-105, 2014.

Pierre Fraigniaud, Cyril Gavoille, David Ilcinkas, and Andrzej Pelc. Distributed computing
with advice: information sensitivity of graph coloring. Distributed Computing, 21(6):395
403, 2009.

Pierre Fraigniaud, Marc Heinrich, and Adrian Kosowski. Local conflict coloring. In Pro-
ceedings of the IEEE 57th Annual Symposium on Foundations of Computer Science, FOCS,
pages 625-634, 2016.

21
/n/n32

33

34

36

37

38

39

40

41

42

43

44

46

Silvio Frischknecht, Stephan Holzer, and Roger Wattenhofer. Networks cannot compute
their diameter in sublinear time. In Proceedings of the ACM-SIAM Symposium on Discrete
Algorithms, SODA, pages 1150-1162, 2012.

Mika Gods and Jukka Suomela. Locally checkable proofs in distributed computing. Theory
of Computing, 12(1):1-33, 2016.

Fabrizio Grandoni, Jochen Kénemann, and Alessandro Panconesi. Distributed weighted
vertex cover via maximal matchings. ACM Trans. Algorithms, 5(1):6:1-6:12, 2008.

Fabrizio Grandoni, Jochen K6nemann, Alessandro Panconesi, and Mauro Sozio. A primal-
dual bicriteria distributed algorithm for capacitated vertex cover. SIAM J. Comput.,
38(3):825-840, 2008.

Michal Hanckowiak, Michal Karonski, and Alessandro Panconesi. On the distributed com-
plexity of computing maximal matchings. SIAM J. Discrete Math., 15(1):41-57, 2001.

David G. Harris, Johannes Schneider, and Hsin-Hao Su. Distributed (A+1)-coloring in
sublogarithmic rounds. In Proceedings of the 48th Annual ACM SIGACT Symposium on
Theory of Computing, STOC, pages 465-478, 2016.

Monika Henzinger, Sebastian Krinninger, and Danupon Nanongkai. A deterministic almost-
tight distributed algorithm for approximating single-source shortest paths. In Proceedings
of the 48th Annual ACM SIGACT Symposium on Theory of Computing, STOC, pages
489-498, 2016.

Stephan Holzer, David Peleg, Liam Roditty, and Roger Wattenhofer. Distributed 3/2-
approximation of the diameter. In Proceedings of the 28th International Symposium on
Distributed Computing, DISC, pages 562-564, 2014.

Stephan Holzer and Nathan Pinsker. Approximation of distances and shortest paths in the
broadcast congest clique. In Proceedings of the 19th International Conference on Principles
of Distributed Systems, OPODIS, pages 6:1-6:16, 2015.

Stephan Holzer and Roger Wattenhofer. Optimal distributed all pairs shortest paths and
applications. In Proceedings of the ACM Symposium on Principles of Distributed Comput-
ing, PODC, pages 355-364, 2012.

Qiang-Sheng Hua, Haoqiang Fan, Lixiang Qian, Ming Ai, Yangyang Li, Xuanhua Shi, and
Hai Jin. Brief announcement: A tight distributed algorithm for all pairs shortest paths
and applications. In Proceedings of the 28th ACM Symposium on Parallelism in Algorithms
and Architectures, SPAA, pages 439-441, 2016.

Allan Grgnlund Jorgensen and Seth Pettie. Threesomes, degenerates, and love triangles.
In Proceedings of the 55th IEEE Annual Symposium on Foundations of Computer Science,
FOCS, pages 621-630, 2014.

Samir Khuller, Uzi Vishkin, and Neal E. Young. A primal-dual parallel approximation
technique applied to weighted set and vertex covers. J. Algorithms, 17(2):280-289, 1994.

Liah Kor, Amos Korman, and David Peleg. Tight bounds for distributed MST verification.
In Proceedings of the 28th International Symposium on Theoretical Aspects of Computer
Science, STACS, pages 69-80, 2011.

Christos Koufogiannakis and Neal E. Young. Distributed and parallel algorithms for
weighted vertex cover and other covering problems. In Proceedings of the 28th Annual
ACM Symposium on Principles of Distributed Computing, PODC, pages 171-179, 2009.

22
/n/nAT

48

49

50

51

52

53

54

56

57

58

59

60

61

62

Fabian Kuhn, Thomas Moscibroda, and Roger Wattenhofer. The price of being near-
sighted. In Proceedings of the Seventeenth Annual ACM-SIAM Symposium on Discrete
Algorithms, SODA, pages 980-989, 2006.

Fabian Kuhn, Thomas Moscibroda, and Roger Wattenhofer. Local computation: Lower
and upper bounds. J. ACM, 63(2):17:1-17:44, 2016.

Eyal Kushilevitz and Noam Nisan. Communication Complexity. Cambridge University
Press, New York, NY, USA, 1997.

Christoph Lenzen and Boaz Patt-Shamir. Fast partial distance estimation and applica-
tions. In Proceedings of the 2015 ACM Symposium on Principles of Distributed Computing,
PODC, 2015.

Christoph Lenzen and David Peleg. Efficient distributed source detection with limited
bandwidth. In Proceedings of the ACM Symposium on Principles of Distributed Computing,
PODC, pages 375-382, 2013.

Christoph Lenzen and Roger Wattenhofer. Leveraging linial’s locality limit. In Proceedings
of the 22nd International Symposium on Distributed Computing, DISC, pages 394-407,
2008.

Nathan Linial. Locality in distributed graph algorithms. SIAM J. Comput., 21(1):193-201,
1992.

Daniel Marx and Michal Pilipezuk. Everything you always wanted to know about the
parameterized complexity of subgraph isomorphism (but were afraid to ask). In Proceedings
of the 31st International Symposium on Theoretical Aspects of Computer Science, STACS,
pages 542-553, 2014.

Thomas Moscibroda and Roger Wattenhofer. Coloring unstructured radio networks. Dis-
tributed Computing, 21(4):271-284, 2008.

Danupon Nanongkai. Distributed approximation algorithms for weighted shortest paths.
In Proceedings of the Symposium on Theory of Computing, STOC,, pages 565-573, 2014.

Danupon Nanongkai, Atish Das Sarma, and Gopal Pandurangan. A tight unconditional
lower bound on distributed randomwalk computation. In Proceedings of the 30th Annual
ACM Symposium on Principles of Distributed Computing, PODC, pages 257-266, 2011.

Alessandro Panconesi and Romeo Rizzi. Some simple distributed algorithms for sparse
networks. Distributed Computing, 14(2):97-100, 2001.

David Peleg. Distributed Computing: A Locality-Sensitive Approach. Society for Industrial
and Applied Mathematics, Philadelphia, PA, USA, 2000.

David Peleg, Liam Roditty, and Elad Tal. Distributed algorithms for network diameter
and girth. In Proceedings of the 89th International Colloquium on Automata, Languages,
and Programming, ICALP, pages 660-672, 2012.

David Peleg and Vitaly Rubinovich. A near-tight lower bound on the time complexity of
distributed minimum-weight spanning tree construction. SJAM J. Comput., 30(5):1427
1442, 2000.

Seth Pettie and Hsin-Hao Su. Distributed coloring algorithms for triangle-free graphs. Inf.
Comput., 243:263-280, 2015.

23
/n/n[63]

[64]

Valentin Polishchuk and Jukka Suomela. A simple local 3-approximation algorithm for
vertex cover. Inf. Process. Lett., 109(12):642-645, 2009.

Atish Das Sarma, Stephan Holzer, Liah Kor, Amos Korman, Danupon Nanongkai, Gopal
Pandurangan, David Peleg, and Roger Wattenhofer. Distributed verification and hardness
of distributed approximation. STAM J. Comput., 41(5):1235-1265, 2012.

Johannes Schneider and Roger Wattenhofer. Distributed coloring depending on the chro-
matic number or the neighborhood growth. In Proceedings of the 18th International Collo-
quium on Structural Information and Communication Complexity, SIROCCO, pages 246
257, 2011.

Virginia Vassilevska Williams and Ryan Williams. Finding, minimizing, and counting
weighted subgraphs. SIAM J. Comput., 42(3):831-854, 2013.

24
